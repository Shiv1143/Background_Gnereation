{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shiv1143/Background_Gnereation/blob/master/Different_ways_of_conversion_to_pytorch_JIT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution 1"
      ],
      "metadata": {
        "id": "rg5ZJf0JtlI_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this version we are passing three distinct inputs to the model"
      ],
      "metadata": {
        "id": "lzaGvD87uTfO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoCJbGmNr-Cm",
        "outputId": "77a9eba7-8515-4869-94ae-30cc4f2327a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([1, 1])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class RandomModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RandomModel, self).__init__()\n",
        "\n",
        "        # Define layers for each input\n",
        "        self.input_ids_fc = nn.Linear(512, 256)\n",
        "        self.attention_mask_fc = nn.Linear(512, 256)\n",
        "        self.bbox_fc = nn.Linear(512*4, 256)  # Flatten bbox to 1D\n",
        "\n",
        "        # Define common layers\n",
        "        self.common_fc1 = nn.Linear(256*3, 512)\n",
        "        self.common_fc2 = nn.Linear(512, 128)\n",
        "        self.output_fc = nn.Linear(128, 1)  # Output layer\n",
        "\n",
        "        # Define activation functions\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, bbox):\n",
        "        # Pass each input through respective layers\n",
        "        input_ids_out = self.relu(self.input_ids_fc(input_ids))\n",
        "        attention_mask_out = self.relu(self.attention_mask_fc(attention_mask))\n",
        "        bbox_out = self.relu(self.bbox_fc(bbox.view(-1, 512*4)))  # Flatten bbox\n",
        "\n",
        "        # Concatenate the outputs\n",
        "        combined = torch.cat((input_ids_out, attention_mask_out, bbox_out), dim=1)\n",
        "\n",
        "        # Common layers\n",
        "        common_out = self.relu(self.common_fc1(combined))\n",
        "        common_out = self.relu(self.common_fc2(common_out))\n",
        "\n",
        "        # Output layer\n",
        "        output = self.sigmoid(self.output_fc(common_out))\n",
        "\n",
        "        return output\n",
        "\n",
        "# Instantiate the model\n",
        "model = RandomModel()\n",
        "\n",
        "# Example input shapes\n",
        "input_ids = torch.randn(1, 512)\n",
        "attention_mask = torch.randn(1, 512)\n",
        "bbox = torch.randn(1, 512, 4)\n",
        "\n",
        "# Forward pass\n",
        "output = model(input_ids, attention_mask, bbox)\n",
        "print(\"Output shape:\", output.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scripted_model = torch.jit.script(model)"
      ],
      "metadata": {
        "id": "vjUtw6J7sUDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scripted_model.save(\"random_model.pt\")"
      ],
      "metadata": {
        "id": "qB0Qe41otQCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: delete the previously loaded model, so that it does not fit all the models to GPU\n",
        "\n",
        "del scripted_model\n",
        "del model\n",
        "torch.cuda.synchronize()"
      ],
      "metadata": {
        "id": "FH1RujY3tSrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_scripted_model = torch.jit.load(\"random_model.pt\")\n",
        "\n",
        "# Example input shapes\n",
        "input_ids = torch.randn(1, 512)\n",
        "attention_mask = torch.randn(1, 512)\n",
        "bbox = torch.randn(1, 512, 4)"
      ],
      "metadata": {
        "id": "waakXc6WtfHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = loaded_scripted_model(input_ids, attention_mask, bbox)\n",
        "print(\"Output shape:\", output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOeeevlUthuP",
        "outputId": "ab3a6e79-e831-421f-8f07-126b3ba26412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution 2"
      ],
      "metadata": {
        "id": "XQdM3nchtnis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In solution 2, we are passing inputs as a dict instead of passing three different inputs"
      ],
      "metadata": {
        "id": "BQGb_HwRuOkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class RandomModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RandomModel, self).__init__()\n",
        "\n",
        "        # Define layers for each input\n",
        "        self.input_ids_fc = nn.Linear(512, 256)\n",
        "        self.attention_mask_fc = nn.Linear(512, 256)\n",
        "        self.bbox_fc = nn.Linear(512*4, 256)  # Flatten bbox to 1D\n",
        "\n",
        "        # Define common layers\n",
        "        self.common_fc1 = nn.Linear(256*3, 512)\n",
        "        self.common_fc2 = nn.Linear(512, 128)\n",
        "        self.output_fc = nn.Linear(128, 1)  # Output layer\n",
        "\n",
        "        # Define activation functions\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Unpack the dictionary\n",
        "        input_ids = inputs['input_ids']\n",
        "        attention_mask = inputs['attention_mask']\n",
        "        bbox = inputs['bbox']\n",
        "\n",
        "        # Pass each input through respective layers\n",
        "        input_ids_out = self.relu(self.input_ids_fc(input_ids))\n",
        "        attention_mask_out = self.relu(self.attention_mask_fc(attention_mask))\n",
        "        bbox_out = self.relu(self.bbox_fc(bbox.view(-1, 512*4)))  # Flatten bbox\n",
        "\n",
        "        # Concatenate the outputs\n",
        "        combined = torch.cat((input_ids_out, attention_mask_out, bbox_out), dim=1)\n",
        "\n",
        "        # Common layers\n",
        "        common_out = self.relu(self.common_fc1(combined))\n",
        "        common_out = self.relu(self.common_fc2(common_out))\n",
        "\n",
        "        # Output layer\n",
        "        output = self.sigmoid(self.output_fc(common_out))\n",
        "\n",
        "        return output\n",
        "\n",
        "# Instantiate the model\n",
        "model = RandomModel()"
      ],
      "metadata": {
        "id": "GLiERKGhtgZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving to TorchScript\n",
        "\n",
        "example_input_dict = {'input_ids': torch.randn(1, 512),\n",
        "                      'attention_mask': torch.randn(1, 512),\n",
        "                      'bbox': torch.randn(1, 512, 4)}\n",
        "\n",
        "traced_model = torch.jit.trace(model, example_input_dict)\n",
        "\n",
        "traced_model.save(\"random_model_scripted.pt\")"
      ],
      "metadata": {
        "id": "oOu_ljrquYev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_traced_model = torch.jit.load(\"random_model_scripted.pt\")\n",
        "\n",
        "# Example input dictionary\n",
        "input_dict = {'input_ids': torch.randn(1, 512),\n",
        "              'attention_mask': torch.randn(1, 512),\n",
        "              'bbox': torch.randn(1, 512, 4)}\n",
        "\n",
        "# Forward pass\n",
        "output = loaded_traced_model(input_dict)\n",
        "print(\"Output shape:\", output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP9d-yAwuf_m",
        "outputId": "0e7c834c-261c-4841-f60e-838642cd4b20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution 3\n",
        "\n",
        "Input: Dict\n",
        "\n",
        "Output: Dict"
      ],
      "metadata": {
        "id": "DWIlS_78x0J4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class RandomModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RandomModel, self).__init__()\n",
        "\n",
        "        # Define layers for each input\n",
        "        self.input_ids_fc = nn.Linear(512, 256)\n",
        "        self.attention_mask_fc = nn.Linear(512, 256)\n",
        "        self.bbox_fc = nn.Linear(512*4, 256)  # Flatten bbox to 1D\n",
        "\n",
        "        # Define common layers\n",
        "        self.common_fc1 = nn.Linear(256*3, 512)\n",
        "        self.common_fc2 = nn.Linear(512, 128)\n",
        "\n",
        "        # Define output layers for each output key\n",
        "        self.output_fc1 = nn.Linear(128, 1)  # Output layer for 'output1'\n",
        "        self.output_fc2 = nn.Linear(128, 1)  # Output layer for 'output2'\n",
        "\n",
        "        # Define activation functions\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Unpack the dictionary\n",
        "        input_ids = inputs['input_ids']\n",
        "        attention_mask = inputs['attention_mask']\n",
        "        bbox = inputs['bbox']\n",
        "\n",
        "        # Pass each input through respective layers\n",
        "        input_ids_out = self.relu(self.input_ids_fc(input_ids))\n",
        "        attention_mask_out = self.relu(self.attention_mask_fc(attention_mask))\n",
        "        bbox_out = self.relu(self.bbox_fc(bbox.view(-1, 512*4)))  # Flatten bbox\n",
        "\n",
        "        # Concatenate the outputs\n",
        "        combined = torch.cat((input_ids_out, attention_mask_out, bbox_out), dim=1)\n",
        "\n",
        "        # Common layers\n",
        "        common_out = self.relu(self.common_fc1(combined))\n",
        "        common_out = self.relu(self.common_fc2(common_out))\n",
        "\n",
        "        # Output layers for each output key\n",
        "        output1 = self.sigmoid(self.output_fc1(common_out))\n",
        "        output2 = self.sigmoid(self.output_fc2(common_out))\n",
        "\n",
        "        # Construct the output dictionary\n",
        "        output_dict = {'output1': output1, 'output2': output2}\n",
        "\n",
        "        return output_dict\n"
      ],
      "metadata": {
        "id": "ouuT1LLqujiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomModel()"
      ],
      "metadata": {
        "id": "6nwhsGBbyMQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_input_dict = {'input_ids': torch.randn(1, 512),\n",
        "                      'attention_mask': torch.randn(1, 512),\n",
        "                      'bbox': torch.randn(1, 512, 4)}\n",
        "\n",
        "traced_model = torch.jit.trace(model, example_input_dict, strict=False)\n",
        "\n",
        "# Save the TorchScript model to file\n",
        "traced_model.save(\"random_model_scripted_dict.pt\")\n",
        "\n",
        "# Load the TorchScript model from file\n",
        "loaded_traced_model = torch.jit.load(\"random_model_scripted_dict.pt\")"
      ],
      "metadata": {
        "id": "MQtLk4yZx9Qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dict = loaded_traced_model(example_input_dict)"
      ],
      "metadata": {
        "id": "1bbYeWR1yA6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcNqmX8TyE2r",
        "outputId": "18906c4e-3aaa-458e-bc45-913b07edae01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'output1': tensor([[0.5068]], grad_fn=<SigmoidBackward0>),\n",
              " 'output2': tensor([[0.4901]], grad_fn=<SigmoidBackward0>)}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4UBKXQLLyF9L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}